{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a49f782e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Randomized Grid SearchCV\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ea7ecc",
   "metadata": {},
   "source": [
    "---\n",
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e00ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as pl\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.patheffects as mpe\n",
    "%matplotlib inline\n",
    "import mplcyberpunk as mplcp\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import mean_squared_error  \n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c0858b",
   "metadata": {},
   "source": [
    "### End Import Libraries\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9af7a1c",
   "metadata": {},
   "source": [
    "## Regression Models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6d585",
   "metadata": {},
   "source": [
    "* LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75f53524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------- Randomized Grid SearchCV --------------------------------------------------------#\n",
    "def Characteristics_of_LinearRegression():\n",
    "    '''\n",
    "    This function visualize a importance model columns and average of this.\n",
    "    ------------------------------\n",
    "    Parameter(model): ML - Model\n",
    "    ------------------------------\n",
    "    '''\n",
    "    lr = LinearRegression()\n",
    "    #--------------------------------------------------#\n",
    "    poss_coef = lr.coef_[model.coef_ > 0]    \n",
    "    neg_coef = lr.coef_[model.coef_ < 0]   \n",
    "    \n",
    "    poss_avg = np.average(poss_coef)\n",
    "    neg_avg = np.average(neg_coef)\n",
    "    #--------------------------------------------------#\n",
    "    \n",
    "    plt.style.use(\"cyberpunk\") #Background color\n",
    "    pal_red = sns.color_palette(\"flare\") #Color\n",
    "    pal_blue = sns.color_palette(\"Blues\") #Color\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18,8), tight_layout=True) #Size of plot dpi=300 for better quality\n",
    "    \n",
    "    for _ in range(len(lr.coef_)):\n",
    "        if (lr.coef_[_] >= poss_avg) or (lr.coef_[_] <= neg_avg):\n",
    "            if model.lr[_] > 0:\n",
    "                bar1 = ax.bar(lr.feature_names_in_[_], lr.coef_[_], width=0.7, linewidth=3, alpha=0.8, bottom=0, edgecolor=pal_blue[3], color=pal_blue[4])\n",
    "            elif lr.coef_[_] < 0:\n",
    "                bar1 = ax.bar(lr.feature_names_in_[_], lr.coef_[_], width=0.7, linewidth=3, alpha=0.8, bottom=0, edgecolor=pal_red[2], color=pal_red[3])\n",
    "            else:\n",
    "                bar1 = ax.bar(lr.feature_names_in_[_], lr.coef_[_], width=0.7, linewidth=3, alpha=0.8, bottom=0, color='White')\n",
    "        else:\n",
    "            bar1 = ax.bar(model.feature_names_in_[_], model.coef_[_], width=0.7, linewidth=3, alpha=0.8, bottom=0, edgecolor='Silver', color='Snow')\n",
    "\n",
    "    ax.hlines(y = poss_avg, xmin = len(lr.coef_) * 0.12, xmax = model.feature_names_in_[-4], linestyles = 'dashed', color = 'White')\n",
    "    ax.text(lr.feature_names_in_[0], poss_avg, 'Avg Importance Columns', ha ='left', va ='center') \n",
    "    ax.text(lr.feature_names_in_[-1], poss_avg, round(poss_avg,2), ha ='right', va ='center') \n",
    "\n",
    "    ax.hlines(y = neg_avg, xmin = lr.feature_names_in_[3], xmax = len(model.coef_) * 0.88, linestyles = 'dashed', color = 'White')\n",
    "    ax.text(lr.feature_names_in_[-1], neg_avg, 'Avg Importance Columns', ha ='right', va ='center') \n",
    "    ax.text(lr.feature_names_in_[0], neg_avg, round(neg_avg,2), ha ='left', va ='center') \n",
    "\n",
    "    plt.legend([lr], loc=\"upper right\", fontsize=15, labelcolor='Gold')\n",
    "    plt.xlabel('Columns Name', fontsize=20, color='Gold') #Left title\n",
    "    plt.ylabel('Importance Model Values', fontsize=20, color='Gold') #Bottom title\n",
    "    plt.tick_params(axis='y', labelrotation=30, labelsize=12, colors='White')\n",
    "    plt.tick_params(axis='x', width=3, length=7, labelrotation=30, labelsize=7, bottom=True, direction=\"in\", left=False, colors='White') #White\n",
    "    \n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['top'].set_linewidth(0.7)\n",
    "    ax.spines['top'].set_color('Gold')\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['right'].set_linewidth(0.7)\n",
    "    ax.spines['right'].set_color('Gold')\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)     \n",
    "    plt.show()\n",
    "#------------------------------------------- Randomized Grid SearchCV --------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125cdb4",
   "metadata": {},
   "source": [
    "* DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b090993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------- Randomized Grid SearchCV --------------------------------------------------------#\n",
    "def DecisionTreeRegressorModel(dataframe):\n",
    "    '''\n",
    "    This function print RMSE (Train - Test) of Random Grid Search.\n",
    "    Visualize Forecast of last month and RMSE of Drid Search\n",
    "    ------------------------------\n",
    "    Parameter(dataframe): Dataframe\n",
    "    ------------------------------\n",
    "    '''\n",
    "    #hyperparamet_names = []\n",
    "    #hyperparamet_values = []\n",
    "\n",
    "    #for key, value in random_search.best_params_.items():\n",
    "        #print(f\"{key}: {value}\")\n",
    "        #hyperparamet_names.append(key)\n",
    "        #hyperparamet_values.append(value)\n",
    "    \n",
    "    #dataframe_of_model = pd.DataFrame(data=hyperparamet_values, index=hyperparamet_names, columns=['Model_Importance'])\n",
    "    \n",
    "    #------------#\n",
    "    dtr = DecisionTreeRegressor()\n",
    "    #------------#\n",
    "    \n",
    "    def Plot_Of_Last_Months(model):\n",
    "        #------------ Plot ------------#\n",
    "        forecast_index = y_test.index.copy()\n",
    "        forecast_index = pd.to_datetime(forecast_index) #y_test index\n",
    "\n",
    "        plt.style.use(\"cyberpunk\") #Background color\n",
    "        pal_red = sns.color_palette(\"flare\") #Color\n",
    "        pal_blue = sns.color_palette(\"Blues\") #Color\n",
    "        \n",
    "        fig, ax1 = plt.subplots(figsize=(15,5), tight_layout=True) #Size of plot dpi=300 for better quality\n",
    "\n",
    "        ax1.plot(forecast_index, y_test, ls='--', color=pal_red[3])\n",
    "        ax1.plot(forecast_index, forecast_grid_search, color=pal_blue[4])\n",
    "\n",
    "        plt.title('Forecast of DecisionTreeRegressor (Grid - Search)', fontsize=20, color='Gold') #Bottom title\n",
    "        plt.legend(['Actual','Forecast'], loc=\"upper right\", fontsize=15) #Label - Size of plot\n",
    "        plt.tick_params(axis='x', labelrotation=30, labelsize=15, width=10, length=3,  direction=\"in\", colors='White') #Rotation label x and y\n",
    "        plt.tick_params(axis='y', labelrotation=30, labelsize=15, colors='White') #Rotation label x and y\n",
    "        plt.grid(zorder=1, alpha=0.2, linestyle='--', linewidth=0.5, color='darkgrey') #Grid of plot\n",
    "\n",
    "        mplcp.make_lines_glow()\n",
    "\n",
    "        ax1.spines['top'].set_visible(False)\n",
    "        ax1.spines['right'].set_visible(False)\n",
    "        ax1.spines['left'].set_color('White')\n",
    "        ax1.spines['left'].set_linewidth(0.3)\n",
    "        ax1.spines['bottom'].set_color('White')\n",
    "        ax1.spines['bottom'].set_linewidth(0.3)\n",
    "        plt.show()\n",
    "        #------------ Plot ------------#\n",
    "    \n",
    "        #------------ Plot 2,3 ------------#\n",
    "        Metric_data = pd.DataFrame(data={'Train' : [Train_RMSE],\n",
    "                                         'Test' : [Test_RMSE]})\n",
    "        \n",
    "        fig = gridspec.GridSpec(3, 2)\n",
    "        pl.figure(figsize=(15, 12), tight_layout=True)\n",
    "\n",
    "        ax2 = pl.subplot(fig[0, 0])\n",
    "        plt.ylabel('Root Mean Square Error\\nGrid-Search', fontsize=20, color='Gold') #Bottom title\n",
    "    \n",
    "        bar1 = ax2.bar('Train', Train_RMSE, width=0.3, linewidth=3, alpha=0.8, bottom=0, edgecolor=pal_blue[3], color=pal_blue[4])\n",
    "        bar2 = ax2.bar('Test', Test_RMSE, width=0.3, linewidth=3, alpha=0.8, bottom=0, edgecolor=pal_red[2], color=pal_red[3])\n",
    "    \n",
    "        ax2.tick_params(axis='y', labelsize=0) #White\n",
    "        ax2.tick_params(axis='x', width=7, length=12, labelrotation=30, labelsize=15, bottom=True, direction=\"in\", left=False, colors='White') #White\n",
    "        ax2.grid(axis='y', zorder=1, alpha=0.2, linestyle='--', linewidth=0.5, color='darkgrey') #Grid of plot\n",
    "\n",
    "        ax2.text(x=Metric_data.Train.name, y=Metric_data.Train.sum()/2, s=Metric_data.Train[0], color='White', weight='extra bold', ha='center', fontsize=15) #Text of labels\n",
    "        ax2.text(x=Metric_data.Test.name, y=Metric_data.Test.sum()/2, s=Metric_data.Test[0], color='White', weight='extra bold', ha='center', fontsize=15) #Text of labels\n",
    "\n",
    "        mplcp.add_bar_gradient(bars=bar1)\n",
    "        mplcp.add_bar_gradient(bars=bar2)\n",
    "    \n",
    "        ax2.spines['top'].set_visible(False)\n",
    "        ax2.spines['right'].set_visible(False)\n",
    "        ax2.spines['left'].set_visible(False)\n",
    "        ax2.spines['bottom'].set_color('White')\n",
    "        ax2.spines['bottom'].set_linewidth(0.3)\n",
    "    \n",
    "        ax3 = pl.subplot(fig[0, 1])\n",
    "        \n",
    "        ax3.barh('Train', Train_RMSE+0.1, height=0.4, linewidth=3, alpha=0.3, left=0, color=pal_blue[4])\n",
    "        ax3.barh('Test', Test_RMSE+0.1, height=0.4, linewidth=3, alpha=0.3, left=0, color=pal_red[3])\n",
    "    \n",
    "        ax3.barh('Train', Train_RMSE, height=0.3, linewidth=3, alpha=0.8, left=0, edgecolor=pal_blue[3], color=pal_blue[4])\n",
    "        ax3.barh('Test', Test_RMSE, height=0.3, linewidth=3, alpha=0.8, left=0, edgecolor=pal_red[2], color=pal_red[3])\n",
    "    \n",
    "        ax3.legend(['RMSE - Train','RMSE - Test'], loc=\"upper right\", fontsize=15) #Label - Size of plot\n",
    "        ax3.tick_params(axis='y', width=7, length=12, labelrotation=30, labelsize=15, left=True, bottom=False, direction=\"in\", colors='White')\n",
    "        ax3.tick_params(axis='x', labelsize=0) #Rotation label x and y\n",
    "        ax3.grid(axis='x', zorder=1, alpha=0.2, linestyle='--', linewidth=0.5, color='darkgrey') #Grid of plot\n",
    "\n",
    "        ax3.text(x=Metric_data.Train.sum()/2, y=Metric_data.Train.name, s=Metric_data.Train[0], color='White', weight='extra bold', ha='center', fontsize=15) #Text of labels\n",
    "        ax3.text(x=Metric_data.Test.sum()/2, y=Metric_data.Test.name, s=Metric_data.Test[0], color='White', weight='extra bold', ha='center', fontsize=15) #Text of labels\n",
    "\n",
    "        ax3.spines['top'].set_visible(False)\n",
    "        ax3.spines['right'].set_visible(False)\n",
    "        ax3.spines['bottom'].set_visible(False)\n",
    "        ax3.spines['left'].set_color('White')\n",
    "        ax3.spines['left'].set_linewidth(0.3)\n",
    "        plt.show()\n",
    "        #------------ Plot 2,3 ------------#\n",
    "\n",
    "        pl.figure(figsize=(15, 10), tight_layout=True)\n",
    "        ax4 = pl.subplot(fig[1, 0:])\n",
    "        \n",
    "        #Residual for test\n",
    "        residuals_train = y_train - forecast_train_grid_search\n",
    "        residuals_index_train = y_train.index.copy()\n",
    "        residuals_index_train = pd.to_datetime(residuals_index_train)\n",
    "        \n",
    "        #Residual for test\n",
    "        residuals_test = y_test - forecast_grid_search\n",
    "        residuals_index_test = y_test.index.copy()\n",
    "        residuals_index_test = pd.to_datetime(residuals_index_test)\n",
    "\n",
    "        ax4.plot(residuals_index_train, residuals_train, color=pal_blue[4])\n",
    "        ax4.plot(residuals_index_test, residuals_test, color=pal_red[3])\n",
    "        \n",
    "        ax4.legend(['Residuals - Train','Residuals - Test'], loc=\"upper right\", fontsize=15) #Label - Size of plot\n",
    "        plt.tick_params(axis='x', labelrotation=30, labelsize=15, width=10, length=3,  direction=\"in\", colors='White') #Rotation label x and y\n",
    "        plt.tick_params(axis='y', labelrotation=30, labelsize=15, colors='White') #Rotation label x and y\n",
    "        plt.grid(zorder=1, alpha=0.2, linestyle='--', linewidth=0.5, color='darkgrey') #Grid of plot\n",
    "\n",
    "        mplcp.make_lines_glow()\n",
    "\n",
    "        ax4.spines['top'].set_visible(False)\n",
    "        ax4.spines['right'].set_visible(False)\n",
    "        ax4.spines['left'].set_color('White')\n",
    "        ax4.spines['left'].set_linewidth(0.3)\n",
    "        ax4.spines['bottom'].set_color('White')\n",
    "        ax4.spines['bottom'].set_linewidth(0.3)\n",
    "        plt.show()\n",
    "\n",
    "        \n",
    "        \n",
    "    def Train_Test_Split(dataframe):\n",
    "        X = dataframe.iloc[:, 1:]\n",
    "        y = dataframe.iloc[:, 0]\n",
    "        \n",
    "        X_train = X[0:len(X)-30]\n",
    "        y_train = y[0:len(y)-30]\n",
    "        X_test = X[-30:]\n",
    "        y_test = y[-30:]\n",
    "\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, shuffle=False) #80% X_train - 20% X_test\n",
    "    \n",
    "        print('-------------------------')\n",
    "        print('Full Length is: ', len(X))\n",
    "        print('Length of Train is: ', len(X_train))\n",
    "        print('Length of Test is: ', len(X_test))\n",
    "        print('-------------------------\\n\\n\\n')\n",
    "    \n",
    "        return X_train, X_test, y_train, y_test\n",
    "    X_train, X_test, y_train, y_test = Train_Test_Split(dataframe=dataframe)\n",
    "\n",
    "    def RMSE(model, Xtrain, Xtest, ytrain, ytest):\n",
    "        global predict_train, predict_test, Train_RMSE, Test_RMSE\n",
    "        \n",
    "        model.fit(Xtrain,ytrain)\n",
    "        #------------#\n",
    "        predict_train = model.predict(Xtrain)\n",
    "        predict_test = model.predict(Xtest)\n",
    "        #------------#\n",
    "\n",
    "        #print('The Random Hyparameters Tuning is: ', random_search.best_estimator_)\n",
    "        print('------------------------------------------------------------------')\n",
    "\n",
    "        Train_MSE = mean_squared_error(ytrain, predict_train)\n",
    "        Train_RMSE = math.sqrt(Train_MSE)\n",
    "        Train_RMSE = round(Train_RMSE,3)\n",
    "        print('Train-Set Root Mean Square Error: ', Train_RMSE)\n",
    "        \n",
    "        Test_MSE = mean_squared_error(ytest, predict_test)\n",
    "        Test_RMSE = math.sqrt(Test_MSE)\n",
    "        Test_RMSE = round(Test_RMSE,3)\n",
    "        print('Test-Set Root Mean Square Error: ', Test_RMSE)\n",
    "        print('------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "        \n",
    "    def Random_Grid_Search():   \n",
    "        #Define the parameter grid\n",
    "        param_distributions = {\n",
    "            \"max_depth\": [None, 5, 10, 20, 50],\n",
    "            \"min_samples_split\": [2, 5, 10, 20],\n",
    "            \"min_samples_leaf\": [1, 2, 5, 10],\n",
    "            \"max_features\": [None, \"sqrt\", \"log2\"],\n",
    "            \"max_leaf_nodes\": [None, 10, 20, 50],\n",
    "            \"min_impurity_decrease\": [0.0, 0.01, 0.1],\n",
    "            \"criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\"]}\n",
    "\n",
    "        #Set up RandomizedSearchCV\n",
    "        random_search = RandomizedSearchCV(\n",
    "            estimator=dtr,\n",
    "            param_distributions=param_distributions,\n",
    "            n_iter=100,  # Number of random samples\n",
    "            cv=None,        # Number of cross-validation folds\n",
    "            scoring=\"neg_mean_squared_error\",  # Metric to optimize\n",
    "            random_state=0,\n",
    "            n_jobs=-1)    # Use all available cores\n",
    "\n",
    "        print('!!!------------... Start Randomized Search CV ...------------!!!')\n",
    "        for _ in range(0,3,1):\n",
    "            random_search.fit(X_train,y_train)\n",
    "            print('The Random Hyparameters Tuning is: ', random_search.best_estimator_)\n",
    "            RMSE(model=random_search, Xtrain=X_train, Xtest=X_test, ytrain=y_train, ytest=y_test)\n",
    "            if _ < 2:\n",
    "                print('\\n')\n",
    "        print('!!!------------... End Randomized Search CV ...------------!!!\\n\\n\\n')\n",
    "    Random_Grid_Search()\n",
    "\n",
    "    \n",
    "    \n",
    "    def Grid_Search():   \n",
    "        global forecast_train_grid_search, forecast_grid_search\n",
    "        #Define the parameter grid\n",
    "        param_distributions = {\n",
    "            \"max_depth\": [19,20,21],\n",
    "            \"min_samples_leaf\": [1, 2, 3],\n",
    "            \"min_impurity_decrease\": [0.01, 0.02, 0.03],\n",
    "            \"max_leaf_nodes\" : [49, 50, 51]}\n",
    "\n",
    "        #Set up GridSearchCV\n",
    "        grid_search = GridSearchCV(\n",
    "            estimator=dtr,\n",
    "            param_grid=param_distributions,\n",
    "            #verbose=10,\n",
    "            cv=None,\n",
    "            refit=True,\n",
    "            n_jobs=-1)    # Use all available cores\n",
    "    \n",
    "        grid_search.fit(X_train , y_train)\n",
    "        forecast_train_grid_search = grid_search.predict(X_train)\n",
    "        forecast_grid_search = grid_search.predict(X_test)\n",
    "\n",
    "        print('!!!------------... Start Grid Search CV ...------------!!!')\n",
    "        print('The Grid Hyparameters Tuning is: ', grid_search.best_estimator_)\n",
    "        RMSE(model=grid_search, Xtrain=X_train, Xtest=X_test, ytrain=y_train, ytest=y_test)\n",
    "        print('!!!------------... End Grid Search CV ...------------!!!\\n\\n\\n')\n",
    "    \n",
    "        Plot_Of_Last_Months(model=grid_search)\n",
    "    Grid_Search()\n",
    "#------------------------------------------- Randomized Grid SearchCV --------------------------------------------------------#\n",
    "\n",
    "\n",
    "\n",
    "#------------------------------------------- Randomized Grid SearchCV --------------------------------------------------------#\n",
    "def Characteristics_of_DecisionTreeRegressor(model):\n",
    "    '''\n",
    "    This function visualize a importance model columns and average of this.\n",
    "    ------------------------------\n",
    "    Parameter(model): ML - Model\n",
    "    ------------------------------\n",
    "    '''\n",
    "\n",
    "    #--------------------------------------------------#\n",
    "    poss_coef = model.feature_importances_[model.feature_importances_ > 0]    \n",
    "    neg_coef = model.feature_importances_[model.feature_importances_ < 0]   \n",
    "    \n",
    "    poss_avg = np.average(poss_coef)\n",
    "    neg_avg = np.average(neg_coef)\n",
    "    #--------------------------------------------------#\n",
    "    \n",
    "    plt.style.use(\"cyberpunk\") #Background color\n",
    "    pal_red = sns.color_palette(\"flare\") #Color\n",
    "    pal_blue = sns.color_palette(\"Blues\") #Color\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(18,8), tight_layout=True) #Size of plot dpi=300 for better quality\n",
    "    \n",
    "    for _ in range(len(model.feature_importances_)):\n",
    "        if (model.feature_importances_[_] >= poss_avg) or (model.feature_importances_[_] <= neg_avg):\n",
    "            if model.feature_importances_[_] > 0:\n",
    "                bar1 = ax.bar(model.feature_names_in_[_], model.feature_importances_[_], width=0.7, linewidth=3, alpha=0.8, bottom=0, edgecolor=pal_blue[3], color=pal_blue[4])\n",
    "            elif model.feature_importances_[_] < 0:\n",
    "                bar1 = ax.bar(model.feature_names_in_[_], model.feature_importances_[_], width=0.7, linewidth=3, alpha=0.8, bottom=0, edgecolor=pal_red[2], color=pal_red[3])\n",
    "            else:\n",
    "                bar1 = ax.bar(model.feature_names_in_[_], model.feature_importances_[_], width=0.7, linewidth=3, alpha=0.8, bottom=0, color='White')\n",
    "        else:\n",
    "            bar1 = ax.bar(model.feature_names_in_[_], model.feature_importances_[_], width=0.7, linewidth=3, alpha=0.8, bottom=0, edgecolor='Silver', color='Snow')\n",
    "\n",
    "    ax.hlines(y = poss_avg, xmin = len(model.feature_importances_) * 0.12, xmax = model.feature_names_in_[-4], linestyles = 'dashed', color = 'White')\n",
    "    ax.text(model.feature_names_in_[0], poss_avg, 'Avg Importance Columns', ha ='left', va ='center') \n",
    "    ax.text(model.feature_names_in_[-1], poss_avg, round(poss_avg,2), ha ='right', va ='center') \n",
    "\n",
    "    ax.hlines(y = neg_avg, xmin = model.feature_names_in_[3], xmax = len(model.feature_importances_) * 0.88, linestyles = 'dashed', color = 'White')\n",
    "    ax.text(model.feature_names_in_[-1], neg_avg, 'Avg Importance Columns', ha ='right', va ='center') \n",
    "    ax.text(model.feature_names_in_[0], neg_avg, round(neg_avg,2), ha ='left', va ='center') \n",
    "\n",
    "    plt.legend([model], loc=\"upper right\", fontsize=15, labelcolor='Gold')\n",
    "    plt.xlabel('Columns Name', fontsize=20, color='Gold') #Left title\n",
    "    plt.ylabel('Importance Model Values', fontsize=20, color='Gold') #Bottom title\n",
    "    plt.tick_params(axis='y', labelrotation=30, labelsize=12, colors='White')\n",
    "    plt.tick_params(axis='x', width=3, length=7, labelrotation=30, labelsize=7, bottom=True, direction=\"in\", left=False, colors='White') #White\n",
    "    \n",
    "    ax.spines['top'].set_visible(True)\n",
    "    ax.spines['top'].set_linewidth(0.7)\n",
    "    ax.spines['top'].set_color('Gold')\n",
    "    ax.spines['right'].set_visible(True)\n",
    "    ax.spines['right'].set_linewidth(0.7)\n",
    "    ax.spines['right'].set_color('Gold')\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)     \n",
    "    plt.show()\n",
    "#------------------------------------------- Randomized Grid SearchCV --------------------------------------------------------#\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eea9ad",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Randomized Grid SearchCV\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299a8349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
